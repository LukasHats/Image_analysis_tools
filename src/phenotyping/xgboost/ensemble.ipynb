{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_path = '/Users/lukashat/Documents/PhD_Schapiro/Projects/Myeloma_Standal/github/myeloma_standal/phenotyping/ensemble/standard'\n",
    "data = pd.read_csv('/Users/lukashat/Documents/PhD_Schapiro/Projects/Myeloma_Standal/github/myeloma_standal/phenotyping/manual_phenotypes_standard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[\"index\", \"Y_centroid\", \"X_centroid\"], inplace=True)\n",
    "# phenotypes['distance_to_bone'] = phenotypes['distance_to_bone'].replace(-999, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = np.arcsinh(data.iloc[:, 0:32, ])\n",
    "data.drop(columns=data.columns[0:32], inplace=True)\n",
    "data = pd.concat([transformed, data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = 20240611"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['phenotype']\n",
    "X = data.drop(columns=['phenotype'])  # Adjust the column name as per your dataset\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "label_mapping = pd.DataFrame({\n",
    "    'OriginalLabel': label_encoder.classes_,\n",
    "    'EncodedLabel': range(len(label_encoder.classes_))\n",
    "})\n",
    "#label_mapping.to_csv('label_mapping.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(y_encoded)\n",
    "weights = compute_class_weight('balanced', classes=classes, y=y_encoded)\n",
    "class_weights = dict(zip(classes, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 5, shuffle=True, random_state=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost = AdaBoostClassifier(n_estimators=100, learning_rate=0.5, algorithm='SAMME.R', random_state=rs)\n",
    "svm = SVC(kernel='rbf', C=1.0, gamma='scale', probability=True, class_weight=class_weights, random_state=rs)\n",
    "random_forest = RandomForestClassifier(n_estimators=200, max_depth=15, min_samples_split=2, max_features=6, class_weight=class_weights, random_state=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_features = np.zeros((X.shape[0], len(classes) * 3))\n",
    "meta_targets = np.zeros(y_encoded.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y_encoded, test_size=0.10, random_state=rs)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=1/9, random_state=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukashat/miniforge3/envs/xgboost/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukashat/miniforge3/envs/xgboost/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukashat/miniforge3/envs/xgboost/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukashat/miniforge3/envs/xgboost/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukashat/miniforge3/envs/xgboost/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed fold 5\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "for train_index, test_index in kf.split(X_train_val, y_train_val):\n",
    "    X_train_base, X_test_base = X_train_val.iloc[train_index], X_train_val.iloc[test_index]\n",
    "    y_train_base, y_test_base = y_train_val[train_index], y_train_val[test_index]\n",
    "\n",
    "    for clf, meta_start in zip([adaboost, svm, random_forest], range(0, meta_features.shape[1], len(classes))):\n",
    "        clf_clone = clone(clf)\n",
    "        clf_clone.fit(X_train_base, y_train_base)\n",
    "        meta_features[test_index, meta_start:meta_start+len(classes)] = clf_clone.predict_proba(X_test_base)\n",
    "\n",
    "    meta_targets[test_index] = y_test_base\n",
    "    print(f\"Completed fold {fold + 1}\")\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = np.array([class_weights[class_label] for class_label in y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cv_scores = []\n",
    "meta_f1_scores = []\n",
    "all_meta_predictions = []\n",
    "all_y_test_meta = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "xgb_meta = XGBClassifier(n_estimators=600, max_depth=8, learning_rate=0.1, subsample=0.8, colsample_bytree=0.8, use_label_encoder=False, eval_metric='mlogloss', random_state=rs)\n",
    "\n",
    "# Use cross-validation for the meta-classifier\n",
    "\n",
    "for train_index, test_index in kf.split(meta_features):\n",
    "    X_train_meta, X_test_meta = meta_features[train_index], meta_features[test_index]\n",
    "    y_train_meta, y_test_meta = meta_targets[train_index], meta_targets[test_index]\n",
    "    X_train_fold, X_val_fold, y_train_fold, y_val_fold = train_test_split(X_train_meta, y_train_meta, test_size=0.20, random_state=rs)\n",
    "\n",
    "    # Define the validation set for early stopping\n",
    "    eval_set = [(X_val_fold, y_val_fold)]\n",
    "    xgb_meta.fit(X_train_meta, y_train_meta, sample_weight = sample_weights, early_stopping_rounds=60, eval_set=eval_set)\n",
    "    meta_predictions = xgb_meta.predict(X_test_meta)\n",
    "    meta_cv_scores.append(accuracy_score(y_test_meta, meta_predictions))\n",
    "    meta_f1_scores.append(f1_score(y_test_meta, meta_predictions, average='weighted'))\n",
    "    all_meta_predictions.extend(meta_predictions)\n",
    "    all_y_test_meta.extend(y_test_meta)\n",
    "# Display the results\n",
    "print(\"10-fold CV Accuracy for Meta Classifier:\")\n",
    "print(meta_cv_scores)\n",
    "print(\"Mean Accuracy:\", np.mean(meta_cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[12048     1     1    13     1     0    47     0     1    19     6     1\n",
      "    252   127     0]\n",
      " [    7  1635   235   130   204     9     8    37    52   103     1     1\n",
      "     39    10    14]\n",
      " [    2   192  3983    85   151    21    39    30    18    66     5     4\n",
      "     50     7    32]\n",
      " [   29    92    33  4923    99    29    31   153   108   556    17     1\n",
      "    797   161    77]\n",
      " [    0   190   125    82  7446    16    21    51    66   160     2     1\n",
      "     64     4    32]\n",
      " [    0     7    35    85    40  1154    20    40    14    95     5     5\n",
      "     62     4   181]\n",
      " [   51     7    34    40    44    17  2053   267    32   109    12     5\n",
      "    296   200    19]\n",
      " [    2    48    51   234   119    39   267  1693    61   195    11     1\n",
      "     71    19    27]\n",
      " [    2    45    22   164   103     8    35    53  3347   519     3     3\n",
      "    156     4   151]\n",
      " [   13    58    51   523   138    36    98   136   361  9814    14     2\n",
      "    718    88   130]\n",
      " [    4     1    10     9     3     3     9     4     0    11   628    14\n",
      "     52    29     1]\n",
      " [    3     0     0     1     0     2     3     2     0     1    14   286\n",
      "     10    10     1]\n",
      " [  172    34    31   675    92    37   234    37   139   783    82    10\n",
      "  29592   568    69]\n",
      " [  129    12     4   124     7     2   162     3     3   109    46     8\n",
      "    812  5621     2]\n",
      " [    2    17    51   138    55   170    15    36   252   191     4     3\n",
      "    119     3  2255]]\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.96     12517\n",
      "         1.0       0.70      0.66      0.68      2485\n",
      "         2.0       0.85      0.85      0.85      4685\n",
      "         3.0       0.68      0.69      0.69      7106\n",
      "         4.0       0.88      0.90      0.89      8260\n",
      "         5.0       0.75      0.66      0.70      1747\n",
      "         6.0       0.67      0.64      0.66      3186\n",
      "         7.0       0.67      0.60      0.63      2838\n",
      "         8.0       0.75      0.73      0.74      4615\n",
      "         9.0       0.77      0.81      0.79     12180\n",
      "        10.0       0.74      0.81      0.77       778\n",
      "        11.0       0.83      0.86      0.84       333\n",
      "        12.0       0.89      0.91      0.90     32555\n",
      "        13.0       0.82      0.80      0.81      7044\n",
      "        14.0       0.75      0.68      0.72      3311\n",
      "\n",
      "    accuracy                           0.83    103640\n",
      "   macro avg       0.78      0.77      0.78    103640\n",
      "weighted avg       0.83      0.83      0.83    103640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(all_y_test_meta, all_meta_predictions)\n",
    "class_report = classification_report(all_y_test_meta, all_meta_predictions)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print('\\n')\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgboost",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
